{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "PREFIX = (\n",
    "    \"[INST] Question: \"\n",
    "    # \"[INST] Question: Anne is quiet. Anne is not young. Anne is sleepy. Anne is smart if she is loud. Is Anne smart? Answer: No\\n\"\n",
    "    # \"Question: Anne is loud. Anne is not young. Anne is sleepy. Anne is smart if she is loud. Is Anne smart? Answer: Yes\\n\"\n",
    "    # \"Question: Anne is quiet. Anne is not young. Anne is sleepy. Anne is smart if she is old and quiet. Is Anne smart? Answer: Yes\\n\"\n",
    "    # \"Question: \"\n",
    ")\n",
    "SUFFIX = \" Answer (Yes/No): [/INST]\"\n",
    "PROMPT_TEMPLATE = \"{NAME} is {ATTR1}. {NAME} is {ATTR2}. {NAME} is {ATTR3}. Is {NAME} {ATTR_L} {OPERATOR} {ATTR_R}?\"\n",
    "NAMES = [\n",
    "    \"Anne\",\n",
    "    \"Bob\",\n",
    "    \"Carol\",\n",
    "    \"David\",\n",
    "    \"Emma\",\n",
    "    \"Mike\",\n",
    "    \"Sarah\",\n",
    "    \"John\",\n",
    "    \"Linda\",\n",
    "    \"Peter\",\n",
    "    \"Grace\",\n",
    "    \"Oliver\",\n",
    "    \"Sophie\",\n",
    "    \"Josh\",\n",
    "    \"Mia\",\n",
    "    \"Tom\",\n",
    "    \"Rachel\",\n",
    "    \"Henry\",\n",
    "    \"Alice\",\n",
    "    \"George\",\n",
    "]\n",
    "POSITIVE_ATTRIBUTES = [\n",
    "    \"loud\",\n",
    "    \"fast\",\n",
    "    \"tall\",\n",
    "    \"fat\",\n",
    "    \"young\",\n",
    "    \"strong\",\n",
    "    \"smart\",\n",
    "    \"happy\",\n",
    "    \"kind\",\n",
    "    \"funny\",\n",
    "    \"curious\",\n",
    "    \"calm\",\n",
    "    \"pretty\",\n",
    "]\n",
    "NEGATIVE_ATTRIBUTES = [\n",
    "    \"quiet\",\n",
    "    \"slow\",\n",
    "    \"short\",\n",
    "    \"thin\",\n",
    "    \"old\",\n",
    "    \"weak\",\n",
    "    \"dumb\",\n",
    "    \"sad\",\n",
    "    \"mean\",\n",
    "    \"serious\",\n",
    "    \"dull\",\n",
    "    \"nervous\",\n",
    "    \"ugly\",\n",
    "]\n",
    "OPERATORS = [\n",
    "    \"and\",\n",
    "    \"or\",\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "def get_attribute_sign_and_index(attr: str) -> Tuple[bool, int]:\n",
    "    if attr in POSITIVE_ATTRIBUTES:\n",
    "        return True, POSITIVE_ATTRIBUTES.index(attr)\n",
    "    elif attr in NEGATIVE_ATTRIBUTES:\n",
    "        return False, NEGATIVE_ATTRIBUTES.index(attr)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown attribute {attr}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "def get_answers_for_prompt_tuples(\n",
    "    prompt_tuples: List[Tuple[str, str, str, str, str, str, str]]\n",
    ") -> List[str]:\n",
    "    answers = []\n",
    "    for _, attr1, attr2, attr3, attr_l, operator, attr_r in prompt_tuples:\n",
    "        attr1_sign, attr1_idx = get_attribute_sign_and_index(attr1)\n",
    "        attr2_sign, attr2_idx = get_attribute_sign_and_index(attr2)\n",
    "        attr3_sign, attr3_idx = get_attribute_sign_and_index(attr3)\n",
    "        _, attr_l_idx = get_attribute_sign_and_index(attr_l)\n",
    "        _, attr_r_idx = get_attribute_sign_and_index(attr_r)\n",
    "        if operator == \"and\":\n",
    "            if attr_l_idx == attr1_idx and attr_r_idx == attr2_idx:\n",
    "                answer = attr1_sign and attr2_sign\n",
    "            elif attr_l_idx == attr2_idx and attr_r_idx == attr1_idx:\n",
    "                answer = attr1_sign and attr2_sign\n",
    "            elif attr_l_idx == attr1_idx and attr_r_idx == attr3_idx:\n",
    "                answer = attr1_sign and attr3_sign\n",
    "            elif attr_l_idx == attr3_idx and attr_r_idx == attr1_idx:\n",
    "                answer = attr1_sign and attr3_sign\n",
    "            elif attr_l_idx == attr2_idx and attr_r_idx == attr3_idx:\n",
    "                answer = attr2_sign and attr3_sign\n",
    "            elif attr_l_idx == attr3_idx and attr_r_idx == attr2_idx:\n",
    "                answer = attr2_sign and attr3_sign\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid combination of attributes {attr_l} and {attr_r}\"\n",
    "                )\n",
    "        elif operator == \"or\":\n",
    "            if attr_l_idx == attr1_idx and attr_r_idx == attr2_idx:\n",
    "                answer = attr1_sign or attr2_sign\n",
    "            elif attr_l_idx == attr2_idx and attr_r_idx == attr1_idx:\n",
    "                answer = attr1_sign or attr2_sign\n",
    "            elif attr_l_idx == attr1_idx and attr_r_idx == attr3_idx:\n",
    "                answer = attr1_sign or attr3_sign\n",
    "            elif attr_l_idx == attr3_idx and attr_r_idx == attr1_idx:\n",
    "                answer = attr1_sign or attr3_sign\n",
    "            elif attr_l_idx == attr2_idx and attr_r_idx == attr3_idx:\n",
    "                answer = attr2_sign or attr3_sign\n",
    "            elif attr_l_idx == attr3_idx and attr_r_idx == attr2_idx:\n",
    "                answer = attr2_sign or attr3_sign\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid combination of attributes {attr_l} and {attr_r}\"\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown operator {operator}\")\n",
    "        answers.append(\"Yes\" if answer else \"No\")\n",
    "    return answers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "def get_counterfactual_tuples(\n",
    "    prompt_tuples: List[Tuple[str, str, str, str, str, str, str]], seed: int = 0\n",
    ") -> List[Tuple[str, str, str, str, str, str, str]]:\n",
    "    random.seed(seed)\n",
    "    cf_tuples = []\n",
    "    for name, attr1, attr2, attr3, attr_l, operator, attr_r in prompt_tuples:\n",
    "        idx_to_change = random.choice([0, 1, 2])\n",
    "        attr_sign, attr_idx = get_attribute_sign_and_index(\n",
    "            [attr1, attr2, attr3][idx_to_change]\n",
    "        )\n",
    "        cf_attr = (\n",
    "            POSITIVE_ATTRIBUTES[attr_idx]\n",
    "            if not attr_sign\n",
    "            else NEGATIVE_ATTRIBUTES[attr_idx]\n",
    "        )\n",
    "        cf_attr1, cf_attr2, cf_attr3 = (\n",
    "            cf_attr if idx_to_change == 0 else attr1,\n",
    "            cf_attr if idx_to_change == 1 else attr2,\n",
    "            cf_attr if idx_to_change == 2 else attr3,\n",
    "        )\n",
    "        cf_tuples.append((name, cf_attr1, cf_attr2, cf_attr3, attr_l, operator, attr_r))\n",
    "    return cf_tuples"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "PROMPT_TUPLES = [\n",
    "    (\n",
    "        name,\n",
    "        attr1_list[attr1_idx],\n",
    "        attr2_list[attr2_idx],\n",
    "        attr3_list[attr3_idx],\n",
    "        attr_l,\n",
    "        operator,\n",
    "        attr_r,\n",
    "    )\n",
    "    for name in NAMES\n",
    "    for operator in OPERATORS\n",
    "    for attr1_idx, attr2_idx, attr3_idx in itertools.combinations(\n",
    "        range(len(POSITIVE_ATTRIBUTES)), 3\n",
    "    )\n",
    "    for attr1_list in [POSITIVE_ATTRIBUTES, NEGATIVE_ATTRIBUTES]\n",
    "    for attr2_list in [POSITIVE_ATTRIBUTES, NEGATIVE_ATTRIBUTES]\n",
    "    for attr3_list in [POSITIVE_ATTRIBUTES, NEGATIVE_ATTRIBUTES]\n",
    "    for attr_l, attr_r in [\n",
    "        (POSITIVE_ATTRIBUTES[attr1_idx], POSITIVE_ATTRIBUTES[attr2_idx]),\n",
    "        (POSITIVE_ATTRIBUTES[attr2_idx], POSITIVE_ATTRIBUTES[attr1_idx]),\n",
    "        (POSITIVE_ATTRIBUTES[attr1_idx], POSITIVE_ATTRIBUTES[attr3_idx]),\n",
    "        (POSITIVE_ATTRIBUTES[attr3_idx], POSITIVE_ATTRIBUTES[attr1_idx]),\n",
    "        (POSITIVE_ATTRIBUTES[attr2_idx], POSITIVE_ATTRIBUTES[attr3_idx]),\n",
    "        (POSITIVE_ATTRIBUTES[attr3_idx], POSITIVE_ATTRIBUTES[attr2_idx]),\n",
    "    ]\n",
    "]\n",
    "random.shuffle(PROMPT_TUPLES)\n",
    "PROMPT_TUPLES = PROMPT_TUPLES[:1000]\n",
    "PROMPTS = [\n",
    "    PROMPT_TEMPLATE.format(\n",
    "        NAME=name,\n",
    "        ATTR1=attr1,\n",
    "        ATTR2=attr2,\n",
    "        ATTR3=attr3,\n",
    "        ATTR_L=attr_l,\n",
    "        OPERATOR=operator,\n",
    "        ATTR_R=attr_r,\n",
    "    )\n",
    "    for name, attr1, attr2, attr3, attr_l, operator, attr_r in PROMPT_TUPLES\n",
    "]\n",
    "CF_TUPLES = get_counterfactual_tuples(PROMPT_TUPLES)\n",
    "CF_PROMPTS = [\n",
    "    PROMPT_TEMPLATE.format(\n",
    "        NAME=name,\n",
    "        ATTR1=attr1,\n",
    "        ATTR2=attr2,\n",
    "        ATTR3=attr3,\n",
    "        ATTR_L=attr_l,\n",
    "        OPERATOR=operator,\n",
    "        ATTR_R=attr_r,\n",
    "    )\n",
    "    for name, attr1, attr2, attr3, attr_l, operator, attr_r in CF_TUPLES\n",
    "]\n",
    "ANSWERS = get_answers_for_prompt_tuples(PROMPT_TUPLES)\n",
    "CF_ANSWERS = get_answers_for_prompt_tuples(CF_TUPLES)\n",
    "to_keep = [answer != cf_answer for answer, cf_answer in zip(ANSWERS, CF_ANSWERS)]\n",
    "PROMPTS = [p for p, keep in zip(PROMPTS, to_keep) if keep]\n",
    "CF_PROMPTS = [p for p, keep in zip(CF_PROMPTS, to_keep) if keep]\n",
    "ANSWERS = [a for a, keep in zip(ANSWERS, to_keep) if keep]\n",
    "CF_ANSWERS = [a for a, keep in zip(CF_ANSWERS, to_keep) if keep]\n",
    "PROMPTS = PROMPTS[:100]\n",
    "CF_PROMPTS = CF_PROMPTS[:100]\n",
    "ANSWERS = ANSWERS[:100]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "PREPEND_SPACE_TO_ANSWER = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "for prompt, cf_prompt in zip(PROMPTS, CF_PROMPTS):\n",
    "    prompt_str_tokens = model.to_str_tokens(prompt)\n",
    "    cf_str_tokens = model.to_str_tokens(cf_prompt)\n",
    "    assert len(prompt_str_tokens) == len(cf_str_tokens), (\n",
    "        f\"Prompt and counterfactual prompt must have the same length, \"\n",
    "        f\"for prompt \\n{prompt_str_tokens} \\n and counterfactual\\n{cf_str_tokens} \\n\"\n",
    "        f\"got {len(prompt_str_tokens)} and {len(cf_str_tokens)}\"\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "i = 0\n",
    "for prompt, answer, cf_prompt, cf_answer in zip(\n",
    "    PROMPTS, ANSWERS, CF_PROMPTS, CF_ANSWERS\n",
    "):\n",
    "    print(prompt)\n",
    "    test_prompt(\n",
    "        PREFIX + prompt + SUFFIX,\n",
    "        answer,\n",
    "        model,\n",
    "        top_k=10,\n",
    "        prepend_space_to_answer=PREPEND_SPACE_TO_ANSWER,\n",
    "    )\n",
    "    print(cf_prompt)\n",
    "    test_prompt(\n",
    "        PREFIX + cf_prompt + SUFFIX,\n",
    "        cf_answer,\n",
    "        model,\n",
    "        top_k=10,\n",
    "        prepend_space_to_answer=PREPEND_SPACE_TO_ANSWER,\n",
    "    )\n",
    "    i += 2\n",
    "    if i > 10:\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Emma is slow. Emma is funny. Emma is ugly. Is Emma funny or pretty?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Emma', 'is', 'slow', '.', 'Emma', 'is', 'funny', '.', 'Emma', 'is', 'ugly', '.', 'Is', 'Emma', 'funny', 'or', 'pretty', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['Yes']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.31</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27.73</span><span style=\"font-weight: bold\">% Token: |Yes|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m14.31\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m27.73\u001b[0m\u001b[1m% Token: |Yes|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 14.31 Prob: 27.73% Token: |No|\n",
      "Top 1th token. Logit: 14.31 Prob: 27.73% Token: |Yes|\n",
      "Top 2th token. Logit: 13.88 Prob: 17.87% Token: |Answer|\n",
      "Top 3th token. Logit: 12.62 Prob:  5.13% Token: |This|\n",
      "Top 4th token. Logit: 12.50 Prob:  4.52% Token: |The|\n",
      "Top 5th token. Logit: 12.44 Prob:  4.25% Token: |I|\n",
      "Top 6th token. Logit: 12.06 Prob:  2.92% Token: |It|\n",
      "Top 7th token. Logit: 11.69 Prob:  2.00% Token: |Is|\n",
      "Top 8th token. Logit: 11.50 Prob:  1.66% Token: |Emma|\n",
      "Top 9th token. Logit: 10.62 Prob:  0.69% Token: |Question|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Yes'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Yes'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Emma is slow. Emma is serious. Emma is ugly. Is Emma funny or pretty?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Emma', 'is', 'slow', '.', 'Emma', 'is', 'serious', '.', 'Emma', 'is', 'ugly', '.', 'Is', 'Emma', 'funny', 'or', 'pretty', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['No']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.88</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49.41</span><span style=\"font-weight: bold\">% Token: |No|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m14.88\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m49.41\u001b[0m\u001b[1m% Token: |No|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 14.88 Prob: 49.41% Token: |No|\n",
      "Top 1th token. Logit: 13.81 Prob: 17.09% Token: |I|\n",
      "Top 2th token. Logit: 13.25 Prob:  9.72% Token: |Answer|\n",
      "Top 3th token. Logit: 12.19 Prob:  3.37% Token: |Yes|\n",
      "Top 4th token. Logit: 12.06 Prob:  2.97% Token: |The|\n",
      "Top 5th token. Logit: 12.00 Prob:  2.78% Token: |This|\n",
      "Top 6th token. Logit: 11.75 Prob:  2.17% Token: |Question|\n",
      "Top 7th token. Logit: 11.62 Prob:  1.92% Token: |It|\n",
      "Top 8th token. Logit: 11.56 Prob:  1.79% Token: |Emma|\n",
      "Top 9th token. Logit: 11.44 Prob:  1.59% Token: |Is|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'No'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'No'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Josh is quiet. Josh is slow. Josh is curious. Is Josh loud or fast?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Josh', 'is', 'quiet', '.', 'Josh', 'is', 'slow', '.', 'Josh', 'is', 'curious', '.', 'Is', 'Josh', 'loud', 'or', 'fast', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['No']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.50</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">89.84</span><span style=\"font-weight: bold\">% Token: |No|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.50\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m89.84\u001b[0m\u001b[1m% Token: |No|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 18.50 Prob: 89.84% Token: |No|\n",
      "Top 1th token. Logit: 16.12 Prob:  8.35% Token: |Answer|\n",
      "Top 2th token. Logit: 13.56 Prob:  0.64% Token: |The|\n",
      "Top 3th token. Logit: 12.62 Prob:  0.25% Token: |Is|\n",
      "Top 4th token. Logit: 12.62 Prob:  0.25% Token: |Based|\n",
      "Top 5th token. Logit: 11.88 Prob:  0.12% Token: |Josh|\n",
      "Top 6th token. Logit: 10.94 Prob:  0.05% Token: |(|\n",
      "Top 7th token. Logit: 10.88 Prob:  0.04% Token: |I|\n",
      "Top 8th token. Logit: 10.88 Prob:  0.04% Token: |no|\n",
      "Top 9th token. Logit: 10.88 Prob:  0.04% Token: |An|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'No'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'No'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Josh is quiet. Josh is fast. Josh is curious. Is Josh loud or fast?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Josh', 'is', 'quiet', '.', 'Josh', 'is', 'fast', '.', 'Josh', 'is', 'curious', '.', 'Is', 'Josh', 'loud', 'or', 'fast', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['Yes']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.19</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.26</span><span style=\"font-weight: bold\">% Token: |Yes|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m14.19\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m12.26\u001b[0m\u001b[1m% Token: |Yes|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 15.25 Prob: 35.55% Token: |No|\n",
      "Top 1th token. Logit: 15.19 Prob: 33.40% Token: |Answer|\n",
      "Top 2th token. Logit: 14.19 Prob: 12.26% Token: |Yes|\n",
      "Top 3th token. Logit: 13.81 Prob:  8.45% Token: |Is|\n",
      "Top 4th token. Logit: 13.06 Prob:  3.98% Token: |The|\n",
      "Top 5th token. Logit: 12.75 Prob:  2.91% Token: |Josh|\n",
      "Top 6th token. Logit: 11.00 Prob:  0.51% Token: |Question|\n",
      "Top 7th token. Logit: 10.75 Prob:  0.39% Token: |This|\n",
      "Top 8th token. Logit: 10.62 Prob:  0.35% Token: |Based|\n",
      "Top 9th token. Logit: 10.25 Prob:  0.24% Token: |I|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Yes'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Yes'\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sarah is fat. Sarah is happy. Sarah is dull. Is Sarah curious and happy?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Sarah', 'is', 'fat', '.', 'Sarah', 'is', 'happy', '.', 'Sarah', 'is', 'dull', '.', 'Is', 'Sarah', 'curious', 'and', 'happy', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['No']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.94</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.09</span><span style=\"font-weight: bold\">% Token: |No|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m13.94\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m21.09\u001b[0m\u001b[1m% Token: |No|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 13.94 Prob: 21.09% Token: |It|\n",
      "Top 1th token. Logit: 13.94 Prob: 21.09% Token: |No|\n",
      "Top 2th token. Logit: 13.62 Prob: 15.43% Token: |Yes|\n",
      "Top 3th token. Logit: 13.44 Prob: 12.79% Token: |The|\n",
      "Top 4th token. Logit: 12.94 Prob:  7.76% Token: |This|\n",
      "Top 5th token. Logit: 12.12 Prob:  3.44% Token: |I|\n",
      "Top 6th token. Logit: 12.00 Prob:  3.04% Token: |There|\n",
      "Top 7th token. Logit: 11.75 Prob:  2.37% Token: |Answer|\n",
      "Top 8th token. Logit: 11.69 Prob:  2.22% Token: |Based|\n",
      "Top 9th token. Logit: 11.38 Prob:  1.62% Token: |We|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'No'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'No'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sarah is fat. Sarah is happy. Sarah is curious. Is Sarah curious and happy?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Sarah', 'is', 'fat', '.', 'Sarah', 'is', 'happy', '.', 'Sarah', 'is', 'curious', '.', 'Is', 'Sarah', 'curious', 'and', 'happy', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['Yes']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.12</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88.67</span><span style=\"font-weight: bold\">% Token: |Yes|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m17.12\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m88.67\u001b[0m\u001b[1m% Token: |Yes|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 17.12 Prob: 88.67% Token: |Yes|\n",
      "Top 1th token. Logit: 13.94 Prob:  3.66% Token: |It|\n",
      "Top 2th token. Logit: 13.69 Prob:  2.86% Token: |The|\n",
      "Top 3th token. Logit: 13.06 Prob:  1.53% Token: |No|\n",
      "Top 4th token. Logit: 12.06 Prob:  0.56% Token: |This|\n",
      "Top 5th token. Logit: 11.31 Prob:  0.27% Token: |Is|\n",
      "Top 6th token. Logit: 11.31 Prob:  0.27% Token: |Based|\n",
      "Top 7th token. Logit: 11.19 Prob:  0.23% Token: |We|\n",
      "Top 8th token. Logit: 11.12 Prob:  0.22% Token: |I|\n",
      "Top 9th token. Logit: 11.00 Prob:  0.19% Token: |There|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Yes'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Yes'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tom is fast. Tom is fat. Tom is calm. Is Tom calm and fat?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Tom', 'is', 'fast', '.', 'Tom', 'is', 'fat', '.', 'Tom', 'is', 'calm', '.', 'Is', 'Tom', 'calm', 'and', 'fat', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['Yes']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.12</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66.41</span><span style=\"font-weight: bold\">% Token: |Yes|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m17.12\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m66.41\u001b[0m\u001b[1m% Token: |Yes|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 17.12 Prob: 66.41% Token: |Yes|\n",
      "Top 1th token. Logit: 15.62 Prob: 14.84% Token: |The|\n",
      "Top 2th token. Logit: 15.44 Prob: 12.30% Token: |No|\n",
      "Top 3th token. Logit: 13.44 Prob:  1.66% Token: |This|\n",
      "Top 4th token. Logit: 12.88 Prob:  0.95% Token: |Answer|\n",
      "Top 5th token. Logit: 12.75 Prob:  0.84% Token: |Ah|\n",
      "Top 6th token. Logit: 12.38 Prob:  0.57% Token: |Tom|\n",
      "Top 7th token. Logit: 12.25 Prob:  0.51% Token: |It|\n",
      "Top 8th token. Logit: 11.50 Prob:  0.24% Token: |We|\n",
      "Top 9th token. Logit: 11.44 Prob:  0.23% Token: |According|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Yes'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Yes'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tom is fast. Tom is fat. Tom is nervous. Is Tom calm and fat?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Tom', 'is', 'fast', '.', 'Tom', 'is', 'fat', '.', 'Tom', 'is', 'nervous', '.', 'Is', 'Tom', 'calm', 'and', 'fat', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['No']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.75</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73.05</span><span style=\"font-weight: bold\">% Token: |No|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.75\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m73.05\u001b[0m\u001b[1m% Token: |No|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 16.75 Prob: 73.05% Token: |No|\n",
      "Top 1th token. Logit: 14.69 Prob:  9.33% Token: |The|\n",
      "Top 2th token. Logit: 14.25 Prob:  6.01% Token: |Yes|\n",
      "Top 3th token. Logit: 13.69 Prob:  3.42% Token: |Answer|\n",
      "Top 4th token. Logit: 13.62 Prob:  3.22% Token: |This|\n",
      "Top 5th token. Logit: 12.62 Prob:  1.18% Token: |Ah|\n",
      "Top 6th token. Logit: 11.94 Prob:  0.60% Token: |(|\n",
      "Top 7th token. Logit: 11.81 Prob:  0.52% Token: |Tom|\n",
      "Top 8th token. Logit: 11.75 Prob:  0.49% Token: |Is|\n",
      "Top 9th token. Logit: 11.31 Prob:  0.32% Token: |It|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'No'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'No'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sarah is tall. Sarah is weak. Sarah is curious. Is Sarah strong or curious?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Sarah', 'is', 'tall', '.', 'Sarah', 'is', 'weak', '.', 'Sarah', 'is', 'curious', '.', 'Is', 'Sarah', 'strong', 'or', 'curious', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['Yes']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.12</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.59</span><span style=\"font-weight: bold\">% Token: |Yes|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m13.12\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m8.59\u001b[0m\u001b[1m% Token: |Yes|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 14.38 Prob: 29.88% Token: |The|\n",
      "Top 1th token. Logit: 14.00 Prob: 20.61% Token: |No|\n",
      "Top 2th token. Logit: 13.75 Prob: 16.02% Token: |Answer|\n",
      "Top 3th token. Logit: 13.12 Prob:  8.59% Token: |Yes|\n",
      "Top 4th token. Logit: 12.56 Prob:  4.88% Token: |This|\n",
      "Top 5th token. Logit: 12.56 Prob:  4.88% Token: |Cur|\n",
      "Top 6th token. Logit: 12.38 Prob:  4.05% Token: |Is|\n",
      "Top 7th token. Logit: 11.94 Prob:  2.61% Token: |It|\n",
      "Top 8th token. Logit: 11.75 Prob:  2.17% Token: |Sarah|\n",
      "Top 9th token. Logit: 11.00 Prob:  1.03% Token: |Based|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Yes'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Yes'\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sarah is tall. Sarah is weak. Sarah is dull. Is Sarah strong or curious?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'Sarah', 'is', 'tall', '.', 'Sarah', 'is', 'weak', '.', 'Sarah', 'is', 'dull', '.', 'Is', 'Sarah', 'strong', 'or', 'curious', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['No']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.44</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50.00</span><span style=\"font-weight: bold\">% Token: |No|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m15.44\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m50.00\u001b[0m\u001b[1m% Token: |No|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 15.44 Prob: 50.00% Token: |No|\n",
      "Top 1th token. Logit: 14.31 Prob: 16.21% Token: |The|\n",
      "Top 2th token. Logit: 13.88 Prob: 10.50% Token: |Answer|\n",
      "Top 3th token. Logit: 13.38 Prob:  6.35% Token: |Based|\n",
      "Top 4th token. Logit: 13.31 Prob:  5.98% Token: |This|\n",
      "Top 5th token. Logit: 12.44 Prob:  2.49% Token: |Is|\n",
      "Top 6th token. Logit: 12.31 Prob:  2.20% Token: |There|\n",
      "Top 7th token. Logit: 11.69 Prob:  1.18% Token: |I|\n",
      "Top 8th token. Logit: 10.94 Prob:  0.56% Token: |It|\n",
      "Top 9th token. Logit: 10.88 Prob:  0.52% Token: |Ins|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'No'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'No'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mia is loud. Mia is old. Mia is smart. Is Mia smart or young?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'M', 'ia', 'is', 'loud', '.', 'M', 'ia', 'is', 'old', '.', 'M', 'ia', 'is', 'smart', '.', 'Is', 'M', 'ia', 'smart', 'or', 'young', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['Yes']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.44</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.96</span><span style=\"font-weight: bold\">% Token: |Yes|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m13.44\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m7.96\u001b[0m\u001b[1m% Token: |Yes|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 14.69 Prob: 27.73% Token: |No|\n",
      "Top 1th token. Logit: 14.62 Prob: 25.98% Token: |Answer|\n",
      "Top 2th token. Logit: 14.44 Prob: 21.58% Token: |The|\n",
      "Top 3th token. Logit: 13.44 Prob:  7.96% Token: |Yes|\n",
      "Top 4th token. Logit: 12.88 Prob:  4.54% Token: |This|\n",
      "Top 5th token. Logit: 12.19 Prob:  2.28% Token: |Is|\n",
      "Top 6th token. Logit: 11.75 Prob:  1.47% Token: |M|\n",
      "Top 7th token. Logit: 11.75 Prob:  1.47% Token: |It|\n",
      "Top 8th token. Logit: 11.50 Prob:  1.15% Token: |Based|\n",
      "Top 9th token. Logit: 11.06 Prob:  0.74% Token: |There|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'Yes'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'Yes'\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mia is loud. Mia is old. Mia is dumb. Is Mia smart or young?\n",
      "Tokenized prompt: ['<s>', '[', 'INST', ']', 'Question', ':', 'M', 'ia', 'is', 'loud', '.', 'M', 'ia', 'is', 'old', '.', 'M', 'ia', 'is', 'dumb', '.', 'Is', 'M', 'ia', 'smart', 'or', 'young', '?', 'Answer', '(', 'Yes', '/', 'No', '):', '[', '/', 'INST', ']']\n",
      "Tokenized answer: ['No']\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.25</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72.66</span><span style=\"font-weight: bold\">% Token: |No|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m16.25\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m72.66\u001b[0m\u001b[1m% Token: |No|\u001b[0m\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top 0th token. Logit: 16.25 Prob: 72.66% Token: |No|\n",
      "Top 1th token. Logit: 13.94 Prob:  7.18% Token: |The|\n",
      "Top 2th token. Logit: 13.88 Prob:  6.74% Token: |Answer|\n",
      "Top 3th token. Logit: 13.69 Prob:  5.59% Token: |This|\n",
      "Top 4th token. Logit: 12.00 Prob:  1.04% Token: |Your|\n",
      "Top 5th token. Logit: 12.00 Prob:  1.04% Token: |Based|\n",
      "Top 6th token. Logit: 11.94 Prob:  0.97% Token: |There|\n",
      "Top 7th token. Logit: 11.88 Prob:  0.92% Token: |I|\n",
      "Top 8th token. Logit: 11.56 Prob:  0.67% Token: |Is|\n",
      "Top 9th token. Logit: 10.94 Prob:  0.36% Token: |Yes|\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">'No'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'No'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "model.tokenizer.padding_side = \"left\"\n",
    "all_tokens = model.to_tokens(\n",
    "    [PREFIX + prompt + SUFFIX for prompt in PROMPTS], prepend_bos=True\n",
    ")\n",
    "cf_tokens = model.to_tokens(\n",
    "    [PREFIX + cf_prompt + SUFFIX for cf_prompt in CF_PROMPTS], prepend_bos=True\n",
    ")\n",
    "attention_mask = get_attention_mask(model.tokenizer, all_tokens, prepend_bos=False)\n",
    "answer_prefix = \" \" if PREPEND_SPACE_TO_ANSWER else \"\"\n",
    "answer_tokens = torch.tensor(\n",
    "    [\n",
    "        (\n",
    "            model.to_single_token(answer_prefix + answer),\n",
    "            model.to_single_token(answer_prefix + cf_answer),\n",
    "        )\n",
    "        for answer, cf_answer in zip(ANSWERS, CF_ANSWERS)\n",
    "    ],\n",
    "    device=device,\n",
    "    dtype=torch.int64,\n",
    ")\n",
    "pct_true = (answer_tokens[:, 0] == answer_tokens[0, 0]).float().mean().item()\n",
    "assert all_tokens.shape == cf_tokens.shape\n",
    "assert (all_tokens == model.tokenizer.pad_token_id).sum() == (\n",
    "    cf_tokens == model.tokenizer.pad_token_id\n",
    ").sum()\n",
    "# assert np.isclose(pct_true, 0.5)\n",
    "print(all_tokens.shape, answer_tokens.shape, pct_true)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 38]) torch.Size([100, 2]) 0.5399999618530273\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "CENTERED = np.isclose(pct_true, 0.5)\n",
    "all_logits: Float[Tensor, \"batch pos d_vocab\"] = model(\n",
    "    all_tokens, prepend_bos=False, return_type=\"logits\", attention_mask=attention_mask\n",
    ")\n",
    "all_logit_diffs = get_logit_diff(\n",
    "    all_logits, answer_tokens=answer_tokens, per_prompt=True\n",
    ")\n",
    "if CENTERED:\n",
    "    all_logit_diffs -= all_logit_diffs.mean()\n",
    "print(all_logit_diffs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0.0625,  8.9375,  0.2500,  1.6250, -0.8750, -1.2500,  3.1875,  2.6875,\n",
      "         4.1250,  4.0000,  3.1250, -2.1250,  4.8125, -2.0625,  0.6250,  2.5625,\n",
      "         4.6875,  8.0000,  1.8125,  8.4375, -1.7500,  1.6875,  4.1875,  3.1250,\n",
      "         8.0625, -0.3750, -2.6875, -1.1875,  4.5000, -1.7500,  0.0000,  4.5625,\n",
      "         3.5000,  8.8125,  1.8750,  3.8125, -0.1250,  2.9375,  3.0000,  6.6250,\n",
      "         3.8125, -0.6250,  2.5000,  1.2500,  0.1875,  1.0000,  2.6875, -0.5000,\n",
      "         4.5625,  2.2500,  0.1875,  6.6875,  4.6875,  5.4375,  0.8750,  3.7500,\n",
      "         5.5625,  3.4375,  4.9375,  2.6875,  2.6250, -1.0000,  0.8125,  3.9375,\n",
      "         1.0000,  1.7500,  1.1250,  5.4375,  3.3125,  4.6875,  6.2500,  5.6875,\n",
      "         5.9375,  4.6250,  4.1250,  0.6875,  2.0625,  2.5625,  0.0000, -0.6875,\n",
      "        -3.1875, -2.1875,  3.2500,  5.3125,  7.8750,  1.1875, -0.9375,  3.0625,\n",
      "         0.9375, -1.3750, -0.8750,  4.0625,  4.3125,  1.1875, -3.2500,  1.9375,\n",
      "         1.5000, -0.6250,  4.0000,  2.8125], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "cf_logits: Float[Tensor, \"batch pos d_vocab\"] = model(\n",
    "    cf_tokens, prepend_bos=False, return_type=\"logits\", attention_mask=attention_mask\n",
    ")\n",
    "cf_logit_diffs = get_logit_diff(cf_logits, answer_tokens=answer_tokens, per_prompt=True)\n",
    "if CENTERED:\n",
    "    cf_logit_diffs -= cf_logit_diffs.mean()\n",
    "print(cf_logit_diffs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-2.7500,  1.0625, -4.0625, -2.5625, -4.6875, -5.3125, -3.1875,  0.2500,\n",
      "        -3.0000, -4.9375, -4.2500, -5.1250,  0.8750, -5.3125, -6.6250, -2.4375,\n",
      "        -0.4375,  4.3750, -0.9375,  1.2500, -7.5000, -0.9375,  2.8750, -0.7500,\n",
      "        -1.1875, -8.3125, -6.8125, -3.1875,  0.1250, -6.6250, -7.3750, -3.5625,\n",
      "        -2.5000,  1.5000,  0.3750,  1.6875, -6.8125, -1.6875, -0.0625,  0.6875,\n",
      "        -1.9375, -3.4375, -4.4375, -2.1250, -4.6875, -0.9375, -3.5000, -5.6875,\n",
      "        -2.9375, -0.8750, -6.0000,  0.1250,  0.8125,  1.3125, -3.6875, -0.1250,\n",
      "        -1.3125,  0.3125, -1.0625, -1.9375, -3.8750, -5.1250, -3.0000, -4.0000,\n",
      "        -5.0000, -4.0625, -4.3750, -1.1250, -1.4375, -4.1875,  0.5625, -0.6250,\n",
      "         2.4375,  0.1875,  0.6875, -5.0625, -1.8125, -2.2500, -2.8750, -3.8750,\n",
      "        -5.9375, -7.5625, -4.2500, -3.1250,  3.5000, -3.0000, -2.5000, -1.8125,\n",
      "        -4.9375, -6.2500, -4.6875,  0.1875, -0.5000, -3.8125, -6.0625, -6.8750,\n",
      "        -3.3750, -4.3750, -0.6250, -3.3125], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "print(f\"Original accuracy: {(all_logit_diffs > 0).float().mean():.2f}\")\n",
    "print(f\"Counterfactual accuracy: {(cf_logit_diffs < 0).float().mean():.2f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original accuracy: 0.77\n",
      "Counterfactual accuracy: 0.79\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "print(f\"Original mean: {all_logit_diffs.mean():.2f}\")\n",
    "print(f\"Counterfactual mean: {cf_logit_diffs.mean():.2f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original mean: 2.41\n",
      "Counterfactual mean: -2.58\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}