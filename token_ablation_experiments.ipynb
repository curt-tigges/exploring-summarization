{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "ipython.run_line_magic(\"autoreload\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import torch\n",
    "import datasets\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from typing import Dict, Iterable, List, Tuple, Union\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_dataset, tokenize_and_concatenate, get_act_name, test_prompt\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "from utils.circuit_analysis import get_logit_diff\n",
    "from utils.store import load_array, save_array\n",
    "\n",
    "from utils.tokenwise_ablation import (\n",
    "    compute_ablation_modified_loss,\n",
    "    compute_ablation_modified_logit_diff,\n",
    "    load_directions,\n",
    "    get_random_directions,\n",
    "    get_zeroed_dir_vector,\n",
    "    get_layerwise_token_mean_activations\n",
    ")\n",
    "from utils.datasets import OWTData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comma Ablation on Natural Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "MODEL_NAME = \"EleutherAI/pythia-2.8b\"\n",
    "TOKEN_ID = 13\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b225c6b67de54a12953754bc61b5c2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522e3e940e6444f58154b175dce5626a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fd48d75aca4355bf7d52c19a62c4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8400d8108c7149249df6f3078aecb008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d849046628439baa484f7cff253979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-2.8b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=False,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d839d8f5124f40a830e59fadf7bd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8666266d1fbd4cb88a81cc24bd0b0f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651f40ac7e2e4f4aa6cca64de71bcbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/951 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532b199ccd274f698ca5a82785ebc6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/download/download_manager.py:528: FutureWarning: 'num_proc' was deprecated in version 2.6.2 and will be removed in 3.0.0. Pass `DownloadConfig(num_proc=<num_proc>)` to the initializer instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6340f281e812428cabdf452e5c242d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3315b7f5a4d4ba084c70ca452470a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1360208d683f4ff2a4ffa7bf16002ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0feb38ec3a41495b95978f3be9dfc543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bd16aeb2084bb7af2769d8d56ea02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "owt_data = OWTData.from_model(model)\n",
    "owt_data.preprocess_datasets(token_to_ablate=TOKEN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = owt_data.dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'attention_mask', 'positions', 'has_token'],\n",
       "    num_rows: 5475\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  249, 46882,    71,   668,   275,  6176,    13,   533,   253,  2208])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['train'][0]['tokens'][30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', ' Kamp', 'f', '”', ' in', ' Germany', ',', ' but', ' the', ' government']\n"
     ]
    }
   ],
   "source": [
    "print(model.to_str_tokens(datasets['train'][0]['tokens'][30:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(datasets['train'][0]['positions'][30:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "#dataloader = owt_data.get_dataloaders(batch_size=BATCH_SIZE)['train']\n",
    "# subsample dataset\n",
    "smaller_dataset = datasets['train'].select(range(50))\n",
    "owt_small = OWTData.from_model(model)\n",
    "owt_small.dataset_dict['train'] = smaller_dataset\n",
    "smaller_dataloader = owt_small.get_dataloaders(batch_size=BATCH_SIZE)['train']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'attention_mask', 'positions', 'has_token'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5475, 5475)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets['train']), len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9b543ff77c42bfa06498e11602bb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/oskar/projects/exploring-summarization/token_ablation_experiments.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/oskar/projects/exploring-summarization/token_ablation_experiments.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m comma_mean_values \u001b[39m=\u001b[39m get_layerwise_token_mean_activations(model, dataloader, token_id\u001b[39m=\u001b[39;49m\u001b[39m13\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/oskar/projects/exploring-summarization/token_ablation_experiments.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m save_array(comma_mean_values, \u001b[39m'\u001b[39m\u001b[39mcomma_mean_values.npy\u001b[39m\u001b[39m'\u001b[39m, model)\n",
      "File \u001b[0;32m/notebooks/utils/tokenwise_ablation.py:142\u001b[0m, in \u001b[0;36mget_layerwise_token_mean_activations\u001b[0;34m(model, data_loader, token_id, device)\u001b[0m\n\u001b[1;32m    139\u001b[0m token_count: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m _, batch_value \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(data_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data_loader)):\n\u001b[0;32m--> 142\u001b[0m     batch_tokens \u001b[39m=\u001b[39m batch_value[\u001b[39m\"\u001b[39;49m\u001b[39mtokens\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    144\u001b[0m     \u001b[39m# Get binary mask of positions where token_id matches in the batch of tokens\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     token_mask \u001b[39m=\u001b[39m batch_tokens \u001b[39m==\u001b[39m token_id\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "comma_mean_values = get_layerwise_token_mean_activations(model, dataloader, token_id=13, device=device)\n",
    "save_array(comma_mean_values, 'comma_mean_values.npy', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files\n",
    "owt_mean_values = torch.from_numpy(np.load('data/pythia-2.8b/comma_mean_values.npy')).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Loss Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c42276777114606beab5064fe7e32d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heads_to_ablate = [(layer, head) for layer in range(model.cfg.n_layers) for head in range(model.cfg.n_heads)]\n",
    "heads_to_freeze = [(layer, head) for layer in range(model.cfg.n_layers) for head in range(model.cfg.n_heads)]\n",
    "layers_to_ablate = [layer for layer in range(model.cfg.n_layers)]\n",
    "output = compute_ablation_modified_loss(\n",
    "    model, \n",
    "    smaller_dataloader,\n",
    "    layers_to_ablate,\n",
    "    owt_mean_values,\n",
    "    cached=False\n",
    ")\n",
    "\n",
    "#ablated_loss = orig_loss + ablated_loss_diff\n",
    "\n",
    "# orig_accuracy = (orig_ld_list > 0).float().mean()\n",
    "# ablated_accuracy = (ablated_ld_list > 0).float().mean()\n",
    "# freeze_ablated_accuracy = (freeze_ablated_ld_list > 0).float().mean()\n",
    "\n",
    "# print(f\"Original mean logit diff: {orig_ld_list.mean():.4f}\")\n",
    "# print(f\"Original accuracy: {orig_accuracy:.4f}\")\n",
    "# print(\"\\n\")\n",
    "# print(f\"Comma-ablated mean logit diff: {ablated_ld_list.mean():.4f}\")\n",
    "# print(f\"Comma-ablated accuracy: {ablated_accuracy:.4f}\")\n",
    "# print(f\"Percent drop in logit diff with comma ablation: {(orig_ld_list.mean() - ablated_ld_list.mean()) / orig_ld_list.mean() * 100:.2f}%\")\n",
    "# print(f\"Percent drop in accuracy with comma ablation: {(orig_accuracy - ablated_accuracy) / orig_accuracy * 100:.2f}%\")\n",
    "# print(\"\\n\")\n",
    "# print(f\"Attn frozen, comma-ablated mean logit diff: {freeze_ablated_ld_list.mean():.4f}\")\n",
    "# print(f\"Attn frozen, comma-ablated accuracy: {freeze_ablated_accuracy:.4f}\")\n",
    "# print(f\"Percent drop in logit diff with attn frozen, comma ablation: {(orig_ld_list.mean() - freeze_ablated_ld_list.mean()) / orig_ld_list.mean() * 100:.2f}%\")\n",
    "# print(f\"Percent drop in accuracy with attn frozen, comma ablation: {(orig_accuracy - freeze_ablated_accuracy) / orig_accuracy * 100:.2f}%\")\n",
    "# print(\"---------------------------------------------------------\")\n",
    "# print(\"Random direction ablation results:\")\n",
    "# print(f\"Comma-ablated mean logit diff: {ablated_ld_list_rand.mean():.4f}\")\n",
    "# print(f\"Percent drop in logit diff with comma ablation: {(orig_ld_list_rand.mean() - ablated_ld_list_rand.mean()) / orig_ld_list_rand.mean() * 100:.2f}%\")\n",
    "# print(f\"Attn frozen, comma-ablated mean logit diff: {freeze_ablated_ld_list_rand.mean():.4f}\")\n",
    "# print(f\"Percent drop in logit diff with attn frozen, comma ablation: {(orig_ld_list_rand.mean() - freeze_ablated_ld_list_rand.mean()) / orig_ld_list_rand.mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_loss, ablated_loss_diff = output[0], output[1]\n",
    "ablated_loss = orig_loss + ablated_loss_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2679,  0.9327,  0.7349,  1.6650,  2.8340,  4.7207,  2.5980,  0.0159,\n",
       "          2.0307, 12.9145]),\n",
       " tensor([ 0.0000,  0.0000,  0.0000,  0.1548,  0.5523, -1.1104, -0.0629,  0.0478,\n",
       "         -0.4134,  0.0000]),\n",
       " tensor([ 0.2679,  0.9327,  0.7349,  1.8198,  3.3863,  3.6103,  2.5350,  0.0637,\n",
       "          1.6174, 12.9145]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display to 4 decimal places\n",
    "orig_loss[0, 35:45], ablated_loss_diff[0, 35:45], ablated_loss[0, 35:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9327), tensor(0.), tensor(0.9327))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_loss[0][36], ablated_loss_diff[0][36], ablated_loss[0][36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(smaller_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', ' but', ' the', ' government', ' of', ' Bav', 'aria']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_str_tokens(batch['tokens'][0][36:43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
